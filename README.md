ğŸ¤– RagBotX â€“ Advanced RAG Chatbot with GraphRAG & Chat Memory

100% Local â€¢ Private â€¢ Ollama-powered ğŸš€

Upload PDFs, DOCX, or TXT files and get fast, contextual answers with RAG, HyDE, Neural Reranking, GraphRAG, and chat memory.
Runs fully offline with Ollama
 â€” no internet or external APIs needed.

âœ¨ Features

ğŸ“‚ Upload PDF, DOCX, or TXT documents

ğŸ” Hybrid Retrieval with FAISS + reranking

ğŸŒ GraphRAG â€“ builds a Knowledge Graph for deeper context

ğŸ§  Chat Memory â€“ remembers past conversation turns

ğŸ¯ HyDE Query Expansion â€“ better document recall

ğŸ”„ Switch between RAG Mode (contextual Q&A) and Chat Mode (general AI)

ğŸ›ï¸ Customizable settings (model, temperature, max contexts)

ğŸ“¦ Installation & Setup
1ï¸âƒ£ Clone the Repository
git clone https://github.com/siratchauhan/RagBotX.git
cd RagBotX

2ï¸âƒ£ Create a Virtual Environment
# Windows
python -m venv venv
venv\Scripts\activate

# Mac/Linux
python3 -m venv venv
source venv/bin/activate

3ï¸âƒ£ Install Dependencies
pip install --upgrade pip
pip install -r requirements.txt

4ï¸âƒ£ Install Ollama & Pull Models

Download Ollama â†’ https://ollama.ai

Then pull your models:

ollama pull qwen2:0.5b
ollama pull nomic-embed-text


(You can swap models later in .env)

5ï¸âƒ£ Setup Environment Variables

Create a .env file in the project root:

LLM_API_URL=http://localhost:11434

DEFAULT_MODEL=qwen2:0.5b

EMBEDDINGS_MODEL=nomic-embed-text

ENABLE_HYDE=true

ENABLE_RERANKING=true

ENABLE_GRAPH_RAG=true

TEMPERATURE=0.7

MAX_CONTEXTS=3

6ï¸âƒ£ Run Ollama
ollama serve

7ï¸âƒ£ Launch the Chatbot
streamlit run app.py


Open ğŸ‘‰ http://localhost:8501

ğŸ–¥ï¸ How It Works

Upload documents in the sidebar

RagBotX splits & indexes them into a vector database

Queries are expanded (HyDE), matched (FAISS), reranked, and enriched with GraphRAG

Ollama generates final answers, with context + memory

ğŸ“Œ Roadmap

 Suggested follow-up questions in chat

 Support for ChromaDB / Pinecone / Weaviate backends

 Advanced RAG pipelines (basic vs graph-enhanced)

 Export knowledge graphs as JSON

ğŸ¤ Contributing

Pull requests, feature ideas, and bug reports are welcome!

âš¡ Demo Preview



ğŸ”— Repo: https://github.com/siratchauhan/RagBotX

ğŸ’¬ Built with â¤ï¸ using Python, Streamlit, FAISS, LangChain, and Ollama.
